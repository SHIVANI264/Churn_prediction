{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from random import randrange, uniform\n",
    "\n",
    "os.chdir(\"C:/Users/jatin/Desktop/python_edwisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_data.csv\")\n",
    "df.shape\n",
    "\n",
    "# We have 3333 observations of 21 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving a copy of df before applying data pre -processing steps\n",
    "df_one = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the data is loaded , I have to check for missing values as pre- processing step\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "missing_val\n",
    "\n",
    "# there are no mising values we have to go for outlier analysis now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.boxplot(df['number customer service calls'])\n",
    "\n",
    "#df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numeric data\n",
    "cnames = ['account length',  'number vmail messages',\n",
    "       'total day minutes', 'total day calls', 'total day charge',\n",
    "       'total eve minutes', 'total eve calls', 'total eve charge',\n",
    "       'total night minutes', 'total night calls', 'total night charge',\n",
    "       'total intl minutes', 'total intl calls', 'total intl charge',\n",
    "       'number customer service calls']\n",
    "cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cnames:\n",
    "    print(i)\n",
    "    q75, q25 = np.percentile(df.loc[:,i], [75,25])\n",
    "    iqr = q75-q25\n",
    "    min = q25 - 1.5*iqr\n",
    "    max = q75 + 1.5*iqr\n",
    "    df = df.drop(df[df.loc[:,i]<min].index)\n",
    "    df = df.drop(df[df.loc[:,i]>max].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n",
    "# Now after removing ouliers we have 2797 observations of 21 variables\n",
    "# Next step is feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will corelation analysis among independent variables to remove redudant variables\n",
    "\n",
    "df_corr = df.loc[:,cnames]\n",
    "df_corr.shape\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_corr.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "\n",
    "%matplotlib inline\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n",
    "\n",
    "\n",
    "# We have corelation value of 1 for::\n",
    "#total day minutes and total day charge\n",
    "#total night minutes and total night charge\n",
    "#total evening minutes and total evening charge\n",
    "#total intl minutes and total int charges\n",
    "\n",
    "#Hence we will remove total day charge , total night charge,total evening charge and total intl charge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['state',\"area code\",\"phone number\",\"international plan\" ,\"voice mail plan\"]\n",
    "cat_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_names:\n",
    "    print(i)\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df['Churn'], df[i]))\n",
    "    print(p)\n",
    "    \n",
    "    # p value is greater than 0.05 for area code and phone number .Hence we will remove them \n",
    "    # Also state value is 0.02 which is not very significiant and also it contains 51 levels, will remove this as it will not contribute\n",
    "    # for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can eliminate state , area code , phone no . and other numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"state\",\"area code\", \"phone number\",\"total day charge\" ,\"total eve charge\", \"total night charge\" , \"total intl charge\"] , axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.shape\n",
    "\n",
    "#we have removed 7 varibales now ...14 variables with 2797 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = ['account length',  'number vmail messages',\n",
    "       'total day minutes', 'total day calls', \n",
    "       'total eve minutes', 'total eve calls',\n",
    "       'total night minutes', 'total night calls', \n",
    "       'total intl minutes', 'total intl calls', \n",
    "       'number customer service calls']\n",
    "cnames\n",
    "\n",
    "#Feature scaling..like if we go for knn\n",
    "#Nomalisation\n",
    "df_featured = df.copy()\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    df_featured.loc[:,i] = (df.loc[:,i] - np.min(df[i]))/(np.max(df[i]) - np.min(df[i]))\n",
    "df_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting strings to numeric codes for model building for all independent variables\n",
    "for i in range(0, (df.shape[1]-1)):\n",
    "    print(i)\n",
    "    if(df.iloc[:,i].dtypes == 'object'):\n",
    "        df.iloc[:,i] = pd.Categorical(df.iloc[:,i])\n",
    "        #print(marketing_train[[i]])\n",
    "        df.iloc[:,i] = df.iloc[:,i].cat.codes \n",
    "        df.iloc[:,i] = df.iloc[:,i].astype('object')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating train data for x and y\n",
    "x_train = df.values[:, 0:13]\n",
    "x_train\n",
    "y_train = df.values[:,13]\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(x_train, y_train)\n",
    "C50_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading test data from Testdata.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Test_data.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove redundant variables from test data as in train data\n",
    "\n",
    "test = test.drop([\"state\",\"area code\",\"phone number\",\"total day charge\",\"total night charge\", \"total eve charge\",\"total intl charge\"] , axis =1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string values of test data frame to numeric values\n",
    "for i in range(0, (test.shape[1]-1)):\n",
    "    print(i)\n",
    "    if(test.iloc[:,i].dtypes == 'object'):\n",
    "        test.iloc[:,i] = pd.Categorical(test.iloc[:,i])\n",
    "        #print(marketing_train[[i]])\n",
    "        test.iloc[:,i] = test.iloc[:,i].cat.codes \n",
    "        test.iloc[:,i] = test.iloc[:,i].astype('object')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating test values for x and y \n",
    "x_test = test.values[:,0:13]\n",
    "y_test = test.values[:,13]\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C50_Predictions = C50_model.predict(x_test)\n",
    "C50_Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "CM = confusion_matrix(y_test,C50_Predictions)\n",
    "CM\n",
    "CM = pd.crosstab(y_test, C50_Predictions)\n",
    "CM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "Accuracy =((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR = (FN*100)/(FN+TP)\n",
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 50).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_Predictions = RF_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = pd.crosstab(y_test, RF_Predictions)\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = ((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "Accuracy\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR = (FN*100)/(FN+TP)\n",
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Let us prepare data for logistic regression\n",
    "#replace target categories with 0 AND 1s\n",
    "for i in range(0,len(df)):\n",
    "    df.loc[i,'Churn'] = df.loc[i,'Churn'].replace('False', \"0\")\n",
    "    df.loc[i,'Churn'] = df.loc[i,'Churn'].replace('True', \"1\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "df_logit = pd.DataFrame(df['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit['Churn'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames\n",
    "print(cnames)\n",
    "df_logit\n",
    "#Add continous variables\n",
    "df_logit = df_logit.join(df[cnames])\n",
    "df_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now adding categorical variables with dummy encoding\n",
    "\n",
    "##Create dummies for categorical variables\n",
    "cat_names = [\"international plan\" , \"voice mail plan\"]\n",
    "\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(df[i], prefix = i)\n",
    "    df_logit = df_logit.join(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have training set with dummy variables of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column indexes for independent variables\n",
    "train_cols = df_logit.columns[1:16]\n",
    "train_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.asarray(df_logit[train_cols]).dtype\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit[\"Churn\"] = pd.to_numeric(df_logit[\"Churn\"])\n",
    "df_logit['Churn'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "#Built Logistic Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(df_logit['Churn'], df_logit[train_cols]).fit()\n",
    "\n",
    "logit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Now preparing test data \n",
    "for i in range(0,len(test)):   \n",
    "    test.loc[i,'Churn'] = test.loc[i,'Churn'].replace('False', \"0\")\n",
    "    test.loc[i,'Churn'] = test.loc[i,'Churn'].replace('True', \"1\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_logit = pd.DataFrame(test['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logit['Churn'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_logit[\"Churn\"]= pd.to_numeric(test_logit[\"Churn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_logit = test_logit.join(test[cnames])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(test[i],prefix=i)\n",
    "    test_logit = test_logit.join(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "test_logit['Actual_prob'] = logit.predict(test_logit[train_cols])\n",
    "\n",
    "test_logit['ActualVal'] = 1\n",
    "test_logit.loc[test_logit.Actual_prob < 0.5, 'ActualVal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(test_logit['Churn'], test_logit['ActualVal'])\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "A= (TP+TN)*100/(TP+TN+FP+FN)\n",
    "FNR =(FN*100)/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy = 89.02 , false = 73.21 for logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames_new = {\"international plan\",\"voice mail plan\",\"Churn\"}\n",
    "cnames_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, df_featured.shape[1]):\n",
    "    #print(i)\n",
    "    if(df_featured.iloc[:,i].dtypes == 'object'):\n",
    "        df_featured.iloc[:,i] = pd.Categorical(df_featured.iloc[:,i])\n",
    "        #print(marketing_train[[i]])\n",
    "        df_featured.iloc[:,i] = df_featured.iloc[:,i].cat.codes \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_featured.iloc[:,0:13]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_featured.iloc[:,13]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For KNN we will implement df_featured (scaled data)\n",
    "#KNN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 5).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_featured = test.copy()\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    test_featured.loc[:,i] = (test.loc[:,i] - np.min(test[i]))/(np.max(test[i]) - np.min(test[i]))\n",
    "test_featured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test_featured.iloc[:,0:13]\n",
    "y_test= test_featured.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_Predictions = KNN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CM = pd.crosstab(y_test, KNN_Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "A = ((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "FNR= (FN*100)/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Naive Bayes implementation\n",
    "NB_model = GaussianNB().fit(df.iloc[:,0:13], df.iloc[:,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_Predictions = NB_model.predict(test.iloc[:,0:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CM = pd.crosstab(test.iloc[:,13], NB_Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "A=((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "FNR=(FN*100)/(FN+TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
